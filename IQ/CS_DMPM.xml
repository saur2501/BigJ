<?xml version="1.0" encoding="UTF-8"?>
<CS>
    About - this is my DM PM take on different tools and everything. For details, refer to specific xml files - this is just few words for high level understanding.
    <RnD></RnD>
    <Systems>
        <Platforms>
            <Suse></Suse>
        </Platforms>
        <Frameworks></Frameworks>
    </Systems>
    <DevOps>
        <Scrum>
        Daily Scrum
            done status, Blockers, Plans.
        Sprint Review - DMPM
            Demo in review - Presenting a new world - completeness related questions. Curiosity Applications related. Usability related suggestions.
            updates for next sprint
            DoDs
            Done and Spillovers
            Retro - Good Bad Ugly
            what all is done and spillovers.
            productivity loss
        </Scrum>
        <Design>
            <DesignTools>
                <IDE></IDE>
            </DesignTools>
            <Servers>
                <Kafka>
                    DM
                        Kafka
                            Cluster - Group of computers sharing workload for common purpose
                                Broker - Kafka Server
                            zookeeper
                            Topics - a name for kafka stream
                                Partitions - part of topic
                                    Leader - which machine plays leader for a partition - producer consumers talk to that guy
                                    Offset - unique Id for message in partition (sequence id given when messages enter)
                                        current
                                        committed - offset position already processed by a consumer
                                            sync, async
                            Message Record
                        Interactions
                            Producer - app to publish record to topics
                                Producer Scaling - Thread pool.
                            Consumer - app to pull record from topics
                                Consumer Group - a group of consumers acting as a single logical unit
                                    Y? parallel processing a topic; manages partition assignment; can rebalance as per consumer entry exit.
                            Meta - Schema Evolution
                            Stream - client library to process data in kafka (like substitute of spark, storm, etc)
                            Connectors - i/o kafka and systems (Kafka producer separated from App - Kafka Connect to handle producer and consumer part)
                    PM
                        Distributed streaming (platform) - publish subscribe to a record stream, store them, process the stream
                            Fault Tolerance -
                                enabling a system to continue operating properly in the event of failure of some of its components
                                thru replications factor - number of copies
                            CRUD
                        Producer
                            DFD L0 - Send Message
                                Properties Config - configure properties, Serialization for key and value
                                    bootstrap.servers
                                    key.serializer
                                    value.serializer
                                    partition.class
                                    acks - 0 (no ack - loss of messages, high thruput, no retry), 1 (respond back), all (all partition replica should know)
                                    retries, max.in.flight.requests.per.connection
                                    use.synchronous.send
                                    buffer.memory, compression.type, batch.size, linger.ms, client.id, max.request.size
                                Producer Record Creation - with KV to topic, partition, timestamp.
                                    Serializer KV
                                        Create class
                                        Create producer
                                        Create Serializer - implements Serializer(class) and implements serialize - change this if class is changed
                                        Create Deserializer
                                        Create Consumer
                                    Partitioner - Assign Partition
                                        Default
                                            specified then use it
                                            not specified then find the hash - utils.toPositive(utils.murmur2(keybytes)) % #Partitions
                                            no partition and key then round robin
                                        Customer
                                            ...
                                    Partition Buffer - batch
                                Sending
                                    Fire and Forget
                                    Asynchronous Send
                                    Synchronous Send
                                //update the current offset
                                Accept Record Metadata if successful else error reporting and retry.
                            Scaling Kafka Producer - thru threads
                                ...
                        Consumer
                            DFD L0 - Ask for messages, get messages
                            Consumer Group - listen to 1 topic across partitions with no duplication of messages (better than 1 consumer reading from 4 partitions is 4 consumers reading from 4)
                                entry/exit - reassign partition to another consumer;
                                Group coordinator - maintains the list of active consumers
                                    Manage a list of group members
                                    Initiates a re-balance activity (blocked read for all members) - when a list of consumers is modified
                                    Leader executes a re-balance activity
                                    Sends a new partition assignment to consumer
                                    communicate about new assignments to consumer
                            Consumer wrt Consumer Group
                                Properties - heartbeat.interval.ms = 3ms, session.timeout.ms=3ms
                                    enable.auto.commit and auto.commit.interval.ms
                                //subscribe to topic
                                Connect to group coordinator
                                Join the group (group.id property)
                                    Sends heartbeat
                                Receives partition assignment - which partition to which group - strategies - range, round robin
                                fetches you messages
                                    current offset, committed offset
                                    Poll for records
                                    commit the read records with broker
                                        what if rebalance triggered just b4 commit - maintain offset of processed record, commit when rebalance is triggered
                                        consumerRebalanceListener - onPartitionsRevoked, onPartitionsAssigned
                                        Maintain a list of offsets that are processed and ready to be committed (after polling)
                                        commit the offsets when the partitions are going away (onPartitionRevoked call - commitSync the offsets)
                                Automatic group mgmt and partition assignment
                                offset and consumer position control (consumer.seek)
                                And many more things
                        User
                            Deployment - taken care if cloud
                                Kafka download
                                kafka server start - zookeeper and kafka servers
                                    More instances - change broker listeners and logs dir
                                    config properties
                                        broker id, port,
                                        logs.dir - //where all your offset, topic information is stored
                                        delete.topic.enable
                                        zookeeper.connect, auto.create.topic.enable
                                        default.replication.factor, num.partitions
                                        log.retention.ms, log.retention.bytes
                            topic create
                            start producer console to write data
                            start consumer console to read data
                            send and receive messages
                        Vision
                            Apps listening from kafka topic and writing to another kafka topic
                            Kafka for backbone of all the system communications
                            Kafka for Data collection from n sources b4 analytics
                            Kafka to read agnostic to data format and connect across engines
                        Schema Evolution
                            ...
                        JUnit
                            ...
                        Kafka Connect
                            ...
                        Kafka Streaming
                            ...
                    Regex
                        JavaDocs and Eg
                    HelloWorld
                </Kafka>
            </Servers>
            <Framework>
                <Spark>
				Misc as follows
				CS - Spark Connections ways - Excellent Raw Material for DMPM.
					Local
					SSH into the remote clusters and use Spark shell on the remote cluster.
					downsample the data and pull the data to your laptop.
					Remote notebook on a cloud - zepplin, jupyter supported on cloud - but crashes and gotta download.
					Bridge local & remote spark - seamless with spark standalone but yarn gotta copy etc files to local spark - auth problem
					Jupyter notebook kernel called “Sparkmagic” - sends code to/from Spark cluster thru livy (possible to install thru ambari) - but installation, connection, and authentication issues
						sparkmagic introduces Docker containers to solve the problem of auth, installation, etc.
					Problems - other languages to run on cluster, scheduling the run.
						Set up a remote Jupyter server and SSH tunneling
						Set up a cron scheduler
						Set up Airflow
						Set up Kubeflow and other Kubernetes-based solutions
						Bayesnote is a notebook orchestration platform for Jupyter notebook:
					Others - PySpark Gateway
				CS - Spark applications (Documentation Reading) - Excellent raw material for DMPM - also add in LJ.
					run as independent sets of processes on a cluster
					coordinated by the SparkContext object in your main program (called the driver program). ?SparkContext is the framework main driver program which we elicit thru exit call role-reversal (cmp with MapReduce)
					To run on a cluster
						SparkContext can connect to several types of cluster managers (spark standalone, Mesos, YARN) for resource allocation across application.
						Once connected, Spark acquires executors on nodes in the cluster; executors - processes that run computations and store data for your application
						spark sends your application code to the executors.
						SparkContext sends tasks to the executors to run
					application gets its own executor processes in separate JVM from other application's executor processes.
						executor runs in multiple threads with no interference and ability to share with other executor except thru persistence.
						each driver schedules its own tasks.
					Spark is agnostic to the underlying cluster manager - it justs gotta acquire executor processes
					The driver program must listen for and accept incoming connections from its executors throughout its lifetime - so spark.driver.port in network config file.
						driver program must be network addressable from the worker nodes
					driver schedules tasks on the cluster => it should be run close to the worker nodes => Same LAN OR Open RPC to driver and submit operations from nearby.
					Cluster Managers
						Spark - Simple one included with Spark for easy cluster set up.
						YARN - Hadoop2.
						Apache Mesos - General CM which supports Hadoop.
						K8 - OSS auto-deployment, scale, mgmt of containerized apps.
					Submit Applications to Application
						spark-submit script
					Monitoring UI - node:4040 (typically) for tasks, storage, usage.
					Job Scheduling - control over resource allocation both - ...
						across apps (level of CM) - ?resources across applications.
						within apps (if n computations on same spark context) - ?resource usage per application
					Concepts
						Application - User program built on Spark (Driver + Executors on nodes)
						Application jar - user's app as jar - uber jar with dependencies but never hadoop and spark dependencies.
						Driver program - process running the main() function of the application and creating the SparkContext
						Cluster Manager - external service for acquiring resources on the cluster
						Deploy mode - Distinguishes where the driver process runs.
							cluster mode - framework launches the driver inside of the cluster
							client mode - submitter launches the driver outside of the cluster
						Worker Node - Any node that can run application code in the cluster
						Executor - A process launched for an application on a worker node
							The process runs tasks - keeping data in memory or disk storage across them.
						Task - work that will be sent to one executor
						Job - parallel computation consisting of multiple tasks that gets spawned in response to a Spark action (save, collect)
							can see this term in logs.
						Stage - Each job gets divided into smaller sets of tasks called stages that depend on each other
					Submitting Applications - ...
						Bundle dependencies
						Launch apps with spark-submit
							master URL
							Load config from file
						Advanced dependency Management.
                </Spark>
            </Framework>
            <Scrum></Scrum>
        </Design>
        <Development>
            <PL>
                <Scala>

                </Scala>
                <JAVA>
                    JAVA - DM (behavioral abstract study - no DFD levels here)
                        Overview
                            Basics DT
                            Operators
                            Control Flow - Regular ones.
                        Systems - File Handling, Multithreading, Sockets, Security.
                            IO
                        OOP - Inheritance, Polymorphism, Overriding
                            Exception Handling
                        ADT - Imp DT and Data Structures - String, Array, Stream.
                            Collections
                        Functional - From JAVA 8
                            Lambda, callbacks, etc.
                        Misc
                            Important Keywords
                            vs CPP
                            Methods
                            Constructors
                            lambda
                        Libraries - Math, Lang, Time, Network, Image, Advanced, Tuple, Wrapper.
                        Uncat - Internals - Package, Reflections, Garbage Collection, NIO.
                    JAVA PM
                        JAVA Source Code - create JAVA file
                            Main class with static method - containing statements
                            Class Orchestration - OOP concepts over classes.
                                Design Patterns
                            All Class Logic - DSA over statements.
                        JAVA Compile - javac command creates bytecode (.class files - name same as classes not necessarily file names).
                            classpath, dependencies
                        JVM Run - java process on class file to start the run; also jar.
                            uses JIT
                            classpath
                    JAVA Regex
                        PM - Grammar Syntax
                            Application -> Package*
                            Package -> ProgramFile*
                            ProgramFile -> Program
                            Program -> Imports* class+
                            class ->  AccessControlModifier NonAccessModifier class className [Inheritance] { MemberVariable MemberMethod }
                            MemberVariable -> AccessControlModifier NonAccessModifier DataType VariableName [Initialize]?;
                            MemberMethod -> AccessControlModifier NonAccessModifier ReturnType MethodName ( Arguments ) { MethodBody }
                            AccessControlModifier -> default|private|public|protected
                            NonAccessModifier -> static|abstract|final|synchronized|volatile
                            ReturnType -> DataType|ClassName
                            Arguments -> [DataType|ClassName []? ,]*
                            MethodBody -> VariableDeclaration Statements*
                            VariableDeclaration -> DataType LocalVariable [= Variable | Constant]
                            Statements -> (VariableDeclaration | SimpleStatement | ControlStatement | FunctionCall | IO)+
                            ControlStatement -> DecisionStatement | IterativeStatement | ExceptionBlock
                            ExceptionBlock -> try { Statements } catch(ExceptionClass) { Statements } finally { Statements }
                            SimpleStatement -> ( LocalVariable Operator )* LocalVariable	//ignoring unary and ternary.
                            Operator -> Assignment | Arithmetic | Relational | Logical | Bitwise
                            VariableName, MethodName, ClassName, LocalVariable -> Identifier
                            Identifier -> same rules as CPP.
                            DataType -> PrimitiveDataType | NonPrimitiveDataType | UserDefinedDataType | Collection
                            PrimitiveDataType -> ...
                            NonPrimitiveDataType -> Arrays | String.
                            UserDefinedDataType -> ...
                            Collection -> Set | List | Map.
                        RuntimeBehaviors
                            Inheritance -> extends SuperClass | implements Interface
                            Polymorphism -> exact signature called.
                            Overriding -> Method from SuperClass, Dynamic Method Dispatch.
                            Abstraction | Interface
                            Encapsulation
                            Packages
                            ===
                            SuperClass -> ClassName
                    More - JAVA DMPM - For more languages just plug the delta not everything.
                </JAVA>
                <Python>
                    DM
                        Basics
                        IO - DB also
                            open("test.txt", "wb")
                            test_file.write(bytes("Write me to the file\n", 'UTF-8'))
                            test_file.close()
                            test_file = open("test.txt", "r+")
                            text_in_file = test_file.read()
                        Misc - Variables, operators, functions.
                        Control Flow - eg should be moved to grammar portion later in abstract form.
                            normal
                                    a = b // 5; a**2 #comment
                                    a >> 2
                                    a le; b and b >= c
                            selective
                                    if i lt; 5:
                                            print('less')
                                    elif i == 5:
                                            print('equal')
                                    if substring in string:
                                            print('found')
                            iterative
                                    while (count lt; 9):
                                            print('The count is:', count)
                                            count = count + 1
                                    else:
                                            print('loop finished')
                                    for index in range(len(fruits)):	#iterate over list
                                            print('Current fruit :', fruits[index])
                            functions
                                    def func(self, arg):
                                            self.var = arg
                                    abs(-5)
                            others
                                    ''' multiline comment
                                    # single line comment
                                    \ for next line
                                    ' for word " for sentence """ for paragraph.
                        Data Types and regex
                            num - int, hexa, octa, long, float, complex
                                    arithmetic, logical, relational, etc.
                                    typecast - int("5")
                            bool
                                    logical
                            string
                                    concat - *2, +,
                                    substr - [[m]?:[n]?], long_string[-5:]
                                    replace - str.replace("is", "was")
                                    find - string.find(substring)
                                    split - long_string.split(" ")
                                    length - len(str)
                                    misc - capitalize, isalpha, isalnum
                            list - like flexible array
                                    concat - self.result = self.list11 + self.list12 + [1, 2], *4
                                            grocery_list.append('onions'), insert(1, "Pickle"), remove("Pickle"), sort(), reverse(),
                                    substring - self.list11[2:]
                                    length - len(list)
                                    nesting - list of lists - nested_list[1][1]
                            tuple
                                    concat - *2, etc
                                    substring - self.tuple11[1:3]
                                    length - len(tuple)
                                    typecast - list(pi_tuple)
                            dictionary - like struct
                                    getVal - dict1['one'], dict1.get("Pied Piper")
                                    allKeys - tinydict.keys()
                                    allValues - tinydict.values()
                                    replace - super_villains['Pied Piper'] = 'Hartley Rathaway'
                                    length - len(super_villains)
                        OOPS
                            Inheritance - class Dog(Animal): ...; overriding, overloading.
                                class Foo(Bar):
                                    def baz(self, arg):
                                        return super(Foo, self).baz(arg)
                        Exception Handling
                        Collections
                        Django
                        Data Analysis
                        Numpy
                        Pandas
                        ML
                        GUI
                        Libs - OS, Calendar, Timit, etc.
                        Misc, Applications
                    PM - Grammar
                        ...
                </Python>
            </PL>
        </Development>
        <Deployment>
            <GIT_VIM_SHELL></GIT_VIM_SHELL>
            <Maven>
            CS - Maven from LinkedIn Official Learning for DMPM
                maven
                    requisites - java, maven, ide - all path variables.
                    POM - project object model.
                        project management and comprehension tool - original for building.
                        easy, uniform build, provide information, provide guidelines and best practices.
                        support migration.
                        easy to use, great community support, reliable.
                    POM - a set of standards, a project lifecycle, dependency management system, logic for executing plugin goals at defined phases in a lifecycle.
                        project description, unique set of coordinates, project attribs, license.
                        version, authors and dependencies.
                        coordinates = group, artifact, version.
                Default file structures
                    root
                        src, 
                            main
                                java
                                resources
                            test
                                java
                                resources
                        pom.xml
                pom file
                    repositories
                        pluginRepositories - points to plugins used by maven itself.
                        Maven repo - central open source - search.maven.org/#search
                            local repo - at .m2 - all your dependencies and projects in here.
                    profiles - to override configurations
                        this is org specific. like dev org, test org, etc.
                    details - group artifact version.
                    reactors and parent
                        provided versions dependencies and plugins - specify no more properties version and dependencies.
                        reactor is sequence the package sequence.
                        useful for making shared client libraries for web services for eg.
                        observe reaction build sequence b4 starting.
                    properties
                    dependency
                        details and scope is compile by default
                    build - plugins to build your project.
                        plugins - similar to dependency but more coordinates.
                            eg - use java 11.
                        eg - compiler and 3rd party.
                        compiles to bin and moves to target directory and packages it.
                    report - report info about project.
                        surefire report for test coverage.
                        mvn clean package site
                        open target/site/index.html
                    archetype - powerful constructs although not core.
                        project template using maven.
                        specified when starting - useful for making consistent artifacts.
                        speed to market, consistent standards.
                        can create your own for boiler plates.
                Lifecycle - 3 by default - build plugins are of all the lifecycles.
                    clean - cleaning
                    default - main lifecycle
                        Phases in it - to be executed in order.
                            validate, compile, test, package, verify, install, deploy.
                            phase made up of goals.
                            goals are individual tasks in phase.
                            triggered individually - mvn dependency:analyze - specific goal.
                            avoid running full phases.
                        Build plugins are part of all lifecycles - 3 types of them - core, packaging, tools.
                            tools - variety of uses, release, signing, dependency.
                                dependency plugin
                                    see usage - lots you can check.
                                enforcer plugin - force usage like specific java version.
                                rules can be set inside executions section of pom with rules.
                                jarsigner - PKI encryption signing. keystore certificate.
                                    signed jars for using application servers - for security.
                                release plugin
                                    most used. Make it and release it - preparing project for next iteration.
                                More
                                Scope
                                    default - compile.
                                        dependency is always available.
                                        dependency is propagated. when used in dependency - transitive.
                                    provided - similar to compile. won't see dependency in war but at runtime we assume it.
                                        only available on runtime and test classpaths.
                                        common in enterprise but not in cloud - cuz violates 12 factor principle.
                                        not transitive.
                                    runtime - useful when multiple versions of api.
                                        only for execution. not needed for compilation.
                                        only seen in runtime and test classpaths.
                                    test scope - reduce size - needed only for testing. Test compilation and execution classpaths.
                                        unit test frameworks. not transitive.
                                    less common - system - similar to provided but you gotta specify the location.
                                        import - applies to pom files.
                                Transitive dependencies
                                    Dependency of dependencies - only care for what you know not further dependencies.
                                    closest version - degrees of separation from the root.
                                    dependency management section beats closer version.
                                    scope plays a role.
                                    local definitions rules them all.
                                    Tricks
                                        only declare what you need.
                                        validate scope.
                                            use dependency analyse.
                                        consider parent pom to control version.
                                        always declare when risk of breaking.
                                        always declare when risk of security.
                                Dependency management
                                    for orgs to control actual dependencies within it.
                                    paste properties in parent. dependency management in parent.
                                    remove scope and versions from child project.
                                    similarly for plugin management.
                                Dependency plugin
                                    mvn dependency:analyze - tells warnings of what you use in code and get thru transitive dependencies so overly dependent on them not changing things.
                                    mvn dependency:resolve - lists all declared dependencies linearly.
                                    mvn dependency:tree - to show something on our classpath.
                            core most used - jdk to make bytecode, installation to put in m2.
                                deployment to push remote, validation for validating source code.
                                compiler - does compilation of code.
                                    mvn compile and test-compile
                                    configuring it - section. under pluginManagement in the parent pom.
                                deployment - use distributionmanagement tag to push to remote coordinates.
                                    7 hands you a jar file - create a pom from that.
                                    deploy:deploy-file
                                resources - eth you reference is put into your package - css, js, etc from resources.
                                surefire plugin - convert to site doc.
                                    to execute junit tests. halt when it fails.
                                failSage for integration testing.
                                useful for large scale CICD then necessary.
                            packaging - compiled bytecode and package s.t consumable by jvm.
                                jar is default packaging plugin to make jar file which can be loaded by class loader of the jvm.
                                war by web application server.
                                ear - enterpise; shade - for uber jar - more to do with dependency then packaging or build.
                                when you trigger package this internally gets executed.
                                war file - web archive goes into web application server.
                                jar plugin
                                    default plugin.
                    site - documentation generating
                Maven Multi-module
                    IDE Integrations - Maven integrations with IDE from certain version - plugins b4.
                    Inheritance - configuration from parent. parent child.
                        doesn't quote its own coordinate other than artifact.
                        defined from topmost level downwards.
                        multimodule has parent child relationship but also modules tag in the parent.
                        Any child dependencies are defined in parent object (POM)
                        parent can specify commonly used dependencies.
                            inherited projects automatically get them.
                            submodule identifies all projects in the parent project and inheritance is vv.
                    Reactor - when using multi-module it is used
                        collects all available modules.
                        sorts the projects into the correct order.
                        builds in the order.
                        create from IDE - as Maven, parent project.
                        ?it's layered way of modules not packages in the project.
                        IDE - dependencies pulled automatically so just run them in sequence of dependency and parent in last.
                    Maven Profiles
                        provide ability to customize a particular build.
                        can be written for dev, test or deploy.
                        separate envt for different stakeholders.
                        profie provides an alternative set of values.
                        eg - profiles, profile, id for production, build, plugins, plugin, coordinates.
                            config - debug to false.
                    Writing plugins
                        all work is done by plugins - plugin execution framework at heart.
                        every plugin is artifact that has n Mojos - Maven Plain old java objects.
                        Mojo is a goal in Maven - compiler:compile goal is a mojo.
                        3 parts to plugin descriptor - top level config coordinates.
                            declaration of mojos.
                            declaration of dependencies.
                        maven-archetype-mojo to create a plugin.
                        default code comes - change it to make your code.
            Regex
                mvn -v
                commands
                    clean - remove the bytecode files (to ensure deleted source classes are removed)
                    validate - check schema fine.
                    compile - compile sources.
                    test - run tests
                    package - make jar, war, etc.
                    verify - ???
                    install - into local repo.
                    deploy - into central
                Options
                    -DskipTests
                    -o - offline
                Dependency related
                    dependency:resolve
                    dependency:tree - very important for nesting.
                Plugin-specifics
                    mvn eclipse:eclipse
            </Maven>
        </Deployment>
    </DevOps>
    <DataScience>
        <Tools>
            <Excel></Excel>
            <Tableau></Tableau>
            <IDE>
                RStudio, Spyder, Jupyter, pycharm
            </IDE>
            <Hadoop></Hadoop>
            <Tensorflow></Tensorflow>
            <Keras></Keras>
        </Tools>
    </DataScience>
</CS>
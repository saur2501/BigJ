IQ - Actually using the desktops or screens or spaces for different work spaces
    different threads of work at workplace for parallelism and for home also.
Movie - Chhalang
    3S - Stamina, Strength, Speed.
    Chilli on thumb or another problem you give - to hold shorts. It's not easy. Nth is easy - backing out is.
    Any facility you want pay the price for it - guava then dogs, chicken then chase them. Want juice - no, then extract and give to us.
HomeErp - Gift for mama in Udhampur - Scenery.
HomeErp - SRM - Spiritual - Travelled to ekachakra,  mayapur the eating place - the service that they gave.
HomeErp - SRM - sadda pind explored
IQ - Focus on abstract training - concrete is important but fundamentals are most.
CS
    https://dzone.com/articles/kafka-gt-hdfss3-batch-ingestion-through-spark - kafka batch reading.
    set delete.topic.enable to true in config/server.properties
    zookeeper and kafka servers in the background - nohup - but better don't do it cuz these are servers with logs.
    get count in spark faster - df.cache(); df.count()
    Apply function in a class in scala
        https://stackoverflow.com/questions/9737352/what-is-the-apply-function-in-scala#:~:text=apply%20serves%20the%20purpose%20of,Function1%5BInt%2CInt%5D%20.&text=Writing%20f.
IQ - Youtube - Personal branding,
IQ - Debug Decision tree - thru discussions, figure out where the problem is thru checking what's working and what's not.
CS - can't find sca-maven-plugin or fortify one - java 8 - 1 of maven modules had problem - removed it to make maven sync well.
Movie - Chhalang
    Vakil - At least fight b4 accepting defeat. Even if defeat obvious, decision made after fight.
    saam - compare, daam - prize of computer stud, dand - punishment that you don't know, bhed - they don't want your well being.
    team lead by 8 not 80 - congratulate them for minor loss.
        training against dogs helped for run.
    skills but foundation when going gets tough. lesson of perseverence when going gets tough proved to be far valuable to them
    Thank opponent that your arrival - I realized my responsibilities and that I was spoiling them.
        you still are a better coach and gotta learn a lot from you
    e1 wants to be known sportsman - it takes their parents, PTI - our children will become but first we must.
        PTI chaddo election mein khade hovo
Movie - gulabo sitabo
    2 meaning talks - koi tucha chor hi hoga jisne bulb churaya. 
    Not leaving then bulb, chandelier, fuse removal. Sensitive wall - I touched it broke I am leaving.
    Locking rooms. charpayi taken to road in the night -  police complaint.
SQ - Krishna is not good or bad - nor are we supposed to stay till this realm - we gotta transcend to the realm beyond good and bad
    BG Krishna says he is both good and bad but being conditioned we want good or bad in terms of grats - we have to rise beyond.
    Why Krishna did sth to sages in past like Hiranya's time - cuz even they had to rise beyond good and bad in terms of experiences.
    Good experience give a great incentive and thus facilitate progress but so can bad experiences sometimes.
    That doesn't change his being supreme well wisher - cuz best self interest is not getting what we want conditionally but constitutionally.
CS - RnD Thinking - Layers 
    About - Human being is network of and pipelines of the following.
        The idea of distribution or networking (peers and servers) drills down to all the layers.
    [Digitized ]Data Interactions - Producers and Consumers - People, Browsers, Scraping programs, IOT Sensors and Actuators.
        @Senses - read, write, act.
        TOC, Regex, Compilers, NLP, DIP, etc.
    Data Source and Data Sink - Application and Data Servers.
        @Mind - store, recall.
        Standardization - G3 -> G4 languages - SQL doesn't find a way but exploits a standardized way - "what" to standardized "how".
        minor transformations. recall based mostly.
    Data Manipulation and churning - sync or async.
        @Intel - decision making algorithm to get to a desired goal.
        synchronous at runtime (small data), async batch, streaming.
        Standardization - G5 Languages (model -> (initial to end state))
            AI, ML, Give only the model of the problem and current state and end state - it will find the way etc.
            Many of DL applications tend to move to higher layers not this layer exactly (in terms of application and not means)
                Eg - image to details. Sentence to nouns and verbs. Audio to text and vv.
    Identity (max Soul Simulation) - give it layers and need to maximize profit cost functions - leave it free to act in a new modelled reality or system.
        Knowledge about a system and means about a system - Knowledge model given and left free to act - independent or distributed.
        PC lacks life injected into existence layers - like decision but not choice, store recall but not think or feel, etc.
        ML is done by professionals and is not an automated process. 
        When computer does the training process or performs reinforcement learning, that is different.
        Think of a robot given an urge for survival, greed for grats (simulated), social framework based maximized grats.
            Next, think how robot should figure out the the set of problems to further the markov's hierarchical needs.
            Also, given the set of problems, the robot should 
                figure out a set of candidate algorithms to target 
                select the best one
                an ability to adapt at runtime
                all this in collaboration with the changing and well networked environment.
        Now, most of the research focusses on PnC of everything - applied everywhere and standardized in biz interests.
            inter-discipline study for inspiration and mutual applications. Eg - ML was application of statistics to CS.
            Application of something to other domains. Eg - NLP or Image Recognition is application of ML to linguistics or photography.
            Exploration of possibilities - where we are as State of art is and what all is possible - juice it out fully.
CS - IDEA - There should teams chat topic for every backlog which 1 can join or leave anytime.
IQ - JIRA - informal jira also.
    comment - Prayojan. Work Log - Abhidhyeya.
    prayojan status consists challenges and achievements.
    Abhidhyeya consists of done and what to do next.
CS - https://www.linkedin.com/learning/spark-for-machine-learning-ai/introduction-to-spark?u=57692769
CS - Maven from LinkedIn Official Learning for DMPM
    mvnrepository.com aggregates from many sources - not just maven central.
        there would be note below.
        Checkout all the repos that mvnrepository indexes from.
        maven dependencies in the windows were red marked cuz their dependencies could not be downloaded so included the repo of sap.
    maven
        requisites - java, maven, ide - all path variables.
        POM - project object model.
        project management and comprehension tool - original for building.
        easy, uniform build, provide information, provide guidelines and best practices.
            support migration.
            easy to use, great community support, reliable.
        file structures
            root
                src, 
                    main
                        java
                        resources
                    test
                        java
                        resources
                pom.xml
        pom file
            repositories
                pluginRepositories - points to plugins used by maven itself.
            profiles - to override configurations
                this is org specific.
            details - group artifact version.
            reactors and parent
                provided versions dependencies and pligsn - specify no more properties version and dependencies.
                reactor is sequence the package sequence.
                useful for making shared client libraries for web services for eg.
                observe reaction build sequence b4 starting.
            properties
            dependency
                details and scope is compile by default
            build - plugins to build your project.
                plugins - similar to dependency but more coordinates.
                    eg - use java 11.
                eg - compiler and 3rd party.
                compiles to bin and moves to target directory and packages it.
            report - report info about project.
                surefire report for test coverage.
                mvn clean package site
                open target/site/index.html
            archetype - powerful constructs although not core.
                project template using maven.
                specified when starting - useful for making consistent artifacts.
                speed to market, consistent standards.
                can create your own for boiler plates.
        Lifecycle
            3 by default - default, clean, site.
                main one, cleaning, documentation generating.
                all lifecycle has phase - stage in it.
                default has - validate, compile, test, package, verify, install, deploy.
                phase executed in order.
            phase made up of goals.
                goals are individual tasks in phase.
                triggered individually - mvn dependency:analyze - specific goal.
                avoid running full phases.
            Build plugins are part of all lifecycles.
                3 types of them - core, packaging, tools.
                core most used - jdk to make bytecode, installation to put in m2.
                    deployment to push remote, validation for validating source code.
                    compiler - does compilation of code.
                        mvn compile and test-compile
                        configuring it - section. under pluginManagement in the parent pom.
                    deployment - use distributionmanagement tag to push to remote coordinates.
                        7 hands you a jar file - create a pom from that.
                        deploy:deploy-file
                    resources - eth you reference is put into your package - css, js, etc from resources.
                    surefire plugin - convert to site doc.
                        to execute junit tests. halt when it fails.
                    failSage for integration testing.
                    useful for large scale CICD then necessary.
                packaging - compiled bytecode and package s.t consumable by jvm.
                    jar is default packaging plugin to make jar file which can be loaded by class loader of the jvm.
                    war by web application server.
                    ear - enterpise; shade - for uber jar - more to do with dependency then packaging or build.
                    when you trigger package this internally gets executed.
                    war file - web archive goes into web application server.
                    jar plugin
                        default plugin.
                tools - variety of uses, release, signing, dependency.
                    dependency plugin
                        see usage - lots you can check.
                    enforcer plugin - force usage like specific java version.
                    rules can be set inside executions section of pom with rules.
                    jarsigner - PKI encryption signing. keystore certificate.
                        signed jars for using application servers - for security.
                    release plugin
                        most used. Make it and release it - preparing project for next iteration.
                    More
                    Scope
                        default - compile.
                            dependency is always available.
                            dependency is propagated. when used in dependency - transitive.
                        provided - similar to compile. won't see dependency in war but at runtime we assume it.
                            only available on runtime and test classpaths.
                            common in enterprise but not in cloud - cuz violates 12 factor principle.
                            not transitive.
                        runtime - useful when multiple versions of api.
                            only for execution. not needed for compilation.
                            only seen in runtime and test classpaths.
                        test scope - reduce size - needed only for testing. Test compilation and execution classpaths.
                            unit test frameworks. not transitive.
                        less common - system - similar to provided but you gotta specify the location.
                            import - applies to pom files.
                    Transitive dependencies
                        Dependency of dependencies - only care for what you know not further dependencies.
                        closest version - degrees of separation from the root.
                        dependency management section beats closer version.
                        scope plays a role.
                        local definitions rules them all.
                        Tricks
                            only declare what you need.
                            validate scope.
                                use dependency analyse.
                            consider parent pom to control version.
                            always declare when risk of breaking.
                            always declare when risk of security.
                    Dependency management
                        for orgs to control actual dependencies within it.
                        paste properties in parent. dependency management in parent.
                        remove scope and versions from child project.
                        similarly for plugin management.
                    Dependency plugin
                        mvn dependency:analyze - tells warnings of what you use in code and get thru transitive dependencies so overly dependent on them not changing things.
                        mvn dependency:resolve - lists all declared dependencies linearly.
                        mvn dependency:tree - to show something on our classpath.
                Maven repo - central open source - search.maven.org/#search
                    local repo - at .m2 - all your dependencies and projects in here.
                POM - a set of standards, a project lifecycle, dependency management system, logic for executing plugin goals at defined phases in a lifecycle.
                    project description, unique set of coordinates, project attribs, license.
                    version, authors and dependencies.
                    coordinates = group, artifact, version.
                Maven integrations with IDE from certain version - plugins b4.
                Inheritance - configuration from parent. parent child.
                    doesn't quote its own coordinate other than artifact.
                    defined from topmost level downwards.
                    multimodule has parent child relationship but also modules tag in the parent.
                    Any child dependencies are defined in parent object (POM)
                    parent can specify commonly used dependencies.
                        inherited projects automatically get them.
                        submodule identifies all projects in the parent project and inheritance is vv.
                Reactor - when using multi-module it is used
                    collects all available modules.
                    sorts the projects into the correct order.
                    builds in the order.
                    create from IDE - as Maven, parent project.
                    ?it's layered way of modules not packages in the project.
                    IDE - dependencies pulled automatically so just run them in sequence of dependency and parent in last.
                Maven Profiles
                    provide ability to customize a particular build.
                    can be written for dev, test or deploy.
                    separate envt for different stakeholders.
                    profie provides an alternative set of values.
                    eg - profiles, profile, id for production, build, plugins, plugin, coordinates.
                        config - debug to false.
                Writing plugins
                    all work is done by plugins - plugin execution framework at heart.
                    every plugin is artifact that has n Mojos - Maven Plain old java objects.
                    Mojo is a goal in Maven - compiler:compile goal is a mojo.
                    3 parts to plugin descriptor - top level config coordinates.
                        declaration of mojos.
                        declaration of dependencies.
                    maven-archetype-mojo to create a plugin.
                    default code comes - change it to make your code.
PIES - In Master phase of IQ, you gotta be a hackathon guy (innovation comes naturally) - quicker implementer of anything
    no responsibility to create a business but feature devp very fast.
    Regex knowledge so quick feasibility; POC available so quick implementations.
    Transaction phase will be ability to start business or support business - whichever is most rewarding.
    This track is ignoring FDDL mapping with discrete phases cuz former is continuous and should not dependent on latter.
    In Ashram, master is about ?(ability to do anything with resourcefulness) and later ?event plan, management or orchestrate.
    Once master phase starts, stories will start happening cuz it will be applications of eth PIES.
    Of course not at scale but individual short fun stories.
    In transaction those stories become novels or big deals worth talking about as stand alone topics.
    Foundational perspective, master will mark not just ABCD fundamentals but leveraging them actively every day with logs => Stories.
Movie - Harry Potter Series
    3 things for extra life
    7 horcruxes
        Tom Riddle's diary. -> Destroyed by Harry Potter in Harry Potter and the Chamber of Secrets
        Marvolo Gaunt's Ring. -> Destroyed by Albus Dumbledore in Harry Potter and the Half-Blood Prince
        Salazar Slytherin's Locket. -> Destroyed by Ronald Weasley in Harry Potter and the Deathly Hallows Part I with Gryffindor's sword.
        Helga Hufflepuff's Cup. -> Destroyed by Hermione Granger in Harry Potter and the Deathly Hallows Part 2
        Rowena Ravenclaw's Diadem. -> Destroyed by Harry Potter in Harry Potter and the Deathly Hallows Part 2
        Harry Potter (unknown to Voldemort until after he had destroyed it). -> Destroyed in Harry Potter and the Deathly Hallows Part 2
        Nagini the Snake. -> Destroyed by Neville Longbottom in Harry Potter and the Deathly Hallows Part 2
        Lord Voldemort at the hands of Harry Potter at the end of the Battle of Hogwarts and this is in Harry Potter and the Deathly Hallows Part 2
    Philosopher stone - Quirrell's failed attempt to revive Voldemort.
        Difficulties involved in that culmination like walk past 3-headed dog. emotions like snape plottwist.
    Chamber of secrets - Diary's failed attempt to revive itself into real form by extracting energy.
        Basilisk for purpose of purging the school of all Muggle-born students
    prisoner of azkaban
        Azkaban escape, Dementors attack harry and his future version saves him; New prof for defense comes and goes - Actual killer pettigrew escapes.
    Goblet of fire - rebirth made successful thru goblet of fire and game.
    Order of phoenix - Prof in denial and ministry of magic so rebellion org appears. Friend lost by Bellatrix.
    Half blood prince - horcrux hunt starts. Snape casts the killing curse on Dumbledore. Draco face offs.
    deathly hallows - last year all horcruxes found and destroyed. 3 things for extra life to kill 1 horcrux.
CS - Scala plugin configuration
    <plugin>
        <!-- see http://davidb.github.com/scala-maven-plugin -->
        <groupId>net.alchim31.maven</groupId>
        <artifactId>scala-maven-plugin</artifactId>
        <version>3.2.0</version>
        <executions>
            <execution>
                <goals>
                    <goal>compile</goal>
                    <goal>testCompile</goal>
                </goals>
                <configuration>
                    <sourceDir>src/main/scala</sourceDir>
                </configuration>
            </execution>
        </executions>
    </plugin>
IQ - LIB - quick implementation of spark Pi implementation
    lesson learnt - we gotta go through the documentation without which we make silly mistakes. And turn around time of finishing off a simple use case takes huge time.
    So, abstract mastery has to come with documentation and book and same thing applies to master phase as well - every project has its wiki and git readme
        if not there or not clear enough - talk to colleagues every now and then and elicit moments of truths.
PIES - master phase is about speed - urgency - getting stuffs done in a unit time.
    this habit will come from trying speed in everything I do - speed in exercise, speed in bath, speed in sleep, speed in book reading, speed in code implementation, speed in interactions.
CS - Spark applications (Documentation Reading)
    run as independent sets of processes on a cluster
    coordinated by the SparkContext object in your main program (called the driver program). ?SparkContext is the framework main driver program which we elicit thru exit call role-reversal (cmp with MapReduce)
    To run on a cluster
        SparkContext can connect to several types of cluster managers (spark standalone, Mesos, YARN) for resource allocation across application.
        Once connected, Spark acquires executors on nodes in the cluster; executors - processes that run computations and store data for your application
        spark sends your application code to the executors.
        SparkContext sends tasks to the executors to run
    application gets its own executor processes in separate JVM from other application's executor processes.
        executor runs in multiple threads with no interference and ability to share with other executor except thru persistence.
        each driver schedules its own tasks.
    Spark is agnostic to the underlying cluster manager - it justs gotta acquire executor processes
    The driver program must listen for and accept incoming connections from its executors throughout its lifetime - so spark.driver.port in network config file.
        driver program must be network addressable from the worker nodes
    driver schedules tasks on the cluster => it should be run close to the worker nodes => Same LAN OR Open RPC to driver and submit operations from nearby.
    Cluster Managers
        Spark - Simple one included with Spark for easy cluster set up.
        YARN - Hadoop2.
        Apache Mesos - General CM which supports Hadoop.
        K8 - OSS auto-deployment, scale, mgmt of containerized apps.
    Submit Applications to Application
        spark-submit script
    Monitoring UI - node:4040 (typically) for tasks, storage, usage.
    Job Scheduling - control over resource allocation both - ...
        across apps (level of CM) - ?resources across applications.
        within apps (if n computations on same spark context) - ?resource usage per application
    Concepts
        Application - User program built on Spark (Driver + Executors on nodes)
        Application jar - user's app as jar - uber jar with dependencies but never hadoop and spark dependencies.
        Driver program - process running the main() function of the application and creating the SparkContext
        Cluster Manager - external service for acquiring resources on the cluster
        Deploy mode - Distinguishes where the driver process runs.
            cluster mode - framework launches the driver inside of the cluster
            client mode - submitter launches the driver outside of the cluster
        Worker Node - Any node that can run application code in the cluster
        Executor - A process launched for an application on a worker node
            The process runs tasks - keeping data in memory or disk storage across them.
        Task - work that will be sent to one executor
        Job - parallel computation consisting of multiple tasks that gets spawned in response to a Spark action (save, collect)
            can see this term in logs.
        Stage - Each job gets divided into smaller sets of tasks called stages that depend on each other
    Submitting Applications - ...
        Bundle dependencies
        Launch apps with spark-submit
            master URL
            Load config from file
        Advanced dependency Management.
IQ - Alliance between 2 companies is like cross product - SAP X Microsoft OR SAP X Siemens.
CS - Personal Spark Notes - What is PiEstimation Program - PI*r^2 / r^2 - what proportion of random points generated in a square lie inside the circle.
    Think about it - what is the approach of talk in data frame
    this way spark wants its consumers to just talk in terms of current and final state of MR data I/O and it will figure out Map and reduce functions
        basically, standardization not requiring rigorous maths
    MR works as KV input coming as trivial key (rowNum JLT) and rows as values - you give transformations as you like.
        CSV connectors and others are nothing but standardized programs for converting initial KV of (rowNum,lines) into (rowNum, data tuple)
        Think of a simple table operation like filter or select
            how would that translate into MR operation of KV pairs.
            iterate over rows and extract the portion to determine qualification.
            If select also a part of it - then transform the tuple as per columns desired.
        How would group by and having translate - parse group by column and get hash and keep putting them in buckets (= shuffle) and reduce operation on theose buckets as per aggregation. Having is nothing but filter on those aggregations.
            so group by columns will be keys and aggregates waale columns will be values. Shuffle on them and reduce as per aggregations.
    Thus for all practical purposes, the data model and process model which spark wants us to think in terms of - is simplified. It's same old table, row, columns with different names and operations - df, ds, etc.
CS - Spark - Bad symbolic reference to spark in library class - cuz library not included - not required for my code but is required by the libraries.
    same thing applies to all spark connectors - My code doesn't need it but with your configurations, spark code will need it.
    error goes away.
CS - Spark - config signature doesn't match.
    not even required cuz we request spark submit endpoint to run the app - spark endpoint program will invoke our specific app mainclass using the override method is configured to invoke so no problems.
CS - Kibana Logs
    Discover - filter, select.
    Visualize - create visualizations over jobs.
    Dashboard - Organize your visualizations.
    Management
IQ - We can ask questions from other colleagues (esp senior ones), like stack overflow questions.
    your base knowledge, your expectations and results. what debugging you tried and your findings.
    That way another colleagues should be able to solve a problem in less than 5 minutes.
    And don't hesitate to ask anyone for this 5 minutes help.
    And also be willing to offer this 5 mins help to anybody.
    In fact, always prefer 1 minute help over 5 mins help - that saves eb's time - so sth like ping a question for help can make a difference.
CS - IDEA - conceive of ideal logging.
    with all different log levels - think of ability to collapse the logs into hierarchical buckets.
    assuming that hierarchy is respected and logging is ideal - it should take less than 1 minute to solve it.
CS - Spark cluster thru CF comes with
    credentials
    service url - REST endpoints.
    UI Proxy - spark management.
    logs - kibana logs and dashboards.
    history proxy - past jobs.
IQ - You gotta know how to pin point the source.
    Eg - rather than searching with guessed names where spark job must be getting created - better call the spark swagger api classes - it is bound to work.
PIES - Master is like application phase - history study is config.
    historical applications in current times is master.
IQ
    My documentation following was perfect in every case - only scope of improvement was 
        sometimes documentation isn't sufficient - it gives only 1 line of usage and skips another - the other line of usage like batch job, I would do lots of steps delineated for regular line of usage so any reference is a great help.
        Other times, it suggests and problem is with our expectation like cf ssh program should end - no it's like chisel tunner it will stay on until stopped.
    When a senior asks for async job for you - you accept it and you should accept it - we should value their time and eventually we also need to behave like that - async help to others.
        OR help by hints, help by documentation, help by delegation, help by right person reference
CS - Google : cloud foundry remote debug intellij
    debug set to true in env.
        env: JBP_CONFIG_DEBUG: '{enabled: true}'
        cf set-env app1 JBP_CONFIG_DEBUG '{ enabled: true, port: 8000, suspend: true }'
    cf enable-ssh app1
    cf ssh-enabled app1
    cf restage app1
    cf ssh -N -T -L 8000:localhost:8000 app1
    Add remote configuration
CS - https://stackoverflow.com/questions/318239/how-do-i-set-environment-variables-from-java
CS - Mac Default Apps
    Facetime
    Messages
    Photos
    Contacts
    Calendar
    Reminders
    Numbers
    Keynotes
    Pages
    AppStore
    System Preferences
    Self Service
    Apple@SAP
    Privileges
    MS Office - Excel, Word, PPT, OneNote.
CS - Dock or Taskbar Organized
    System utils - Finder, Launchpad.
    Browsers - including postman.
    Editors - IntelliJ, Notes.
    Fun Apps - Facetime, Self Service, etc.
    Other Apps on demand like terminal, media players.
CS - Mac or any OS launch an App - 4 ways - launch pad, shortcuts - taskbar, search - spotlight search, file associations.
IQ - CS - Architect
    For a given use case, make a heuristics diagram for all the possibilities.
    What is presented is print all the paths from root to leaf
PIES - Applications of economics in Foundations
    there is only so much you can achieve on Production Possibilities frontier (PPF) without sharpening the saw and foundational changes.
    so work hard but more importantly learn to work smart and improve the work itself.
    We start from a place where we have measured TME stock which we can exchange or trade in order to achieve overall wellness on the PPF.
    But we should grow the multi-dimensional karmic curve thru practice, techniques, action in stretch zone and foundational improvemtns (stability MOG, etc)
        also innovation, application of other fields and applications into our own.
    Too little of PIES will cause suffering and also too much of PIES will come at a price of others - so trading TME wisely on PPF - get to the point of interest.
        but also stretch it so that the radial distance from the origin increasees - preferably in all the dimensions.
IQ - LIB - if we make stages of our developments then we are a black box - not only we achieve tasks but we make them CICD available for other team members as well.
    so that if for some reason, we change the task, we still had made the contribution to a checkpoint and others can pick from there.
    These stages of development look on jira with task completed but also a deliverable - like wiki page added, git branch created, PR or merged, quality checked, etc.
    Try to have some deliverable coming every mid week (every 2 days) along with some presentation (can be in minutes, even seconds but really important)
    Every day is like a hackathon and we should reflect in state of wow on reflecting on the day after its done.
    All meetings arranged and discussions over sub-tasks level (or different grains as per needs) - topic of the meetings and efforts logged there.
    Master study for a user story also comes under the effort but not curiosity based master exploration
        cuz you can't take scrum responsibility for the latter in work day efforts.
IQ - Our work day is constituted of working on sub-tasks across user stories (OR High level work life)- nothing else.
    It is in sub-tasks execution at a time that we face different challenges at the abstract or master level.
    These challenges should also be noted as the part of user story execution - which will eventually become a tool for analytics.
    At the start of the day or effort - think end result once, and then a set of sub-tasks (across user stories) - a set because we need to preempt for best results.
    it is true that during the execution we may encounter sub-tasks getting spawned but that's ok - just update it in the jira.
